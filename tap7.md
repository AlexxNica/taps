* TAP: 7
* Title: Conformance testing
* Version: 1
* Last-Modified: 01-May-2017
* Author: Vladimir Diaz, Sebastien Awwad
* Status: Draft
* Content-Type: text/markdown
* Created: 20-Jan-2017

# Abstract

[Conformance testing](https://en.wikipedia.org/wiki/Conformance_testing) can
determine whether an implementation meets the requirements set by a
specification.  A tool that helps developers and users test that an
implementation behaves according to the TUF specification does not presently
exist.  Although the reference implementation contains [unit
tests](https://github.com/theupdateframework/tuf/tree/6fde6222c9c6abf905ef4a56cf56fe35c4a85e14/tests)
that verify correct behavior, such as updating metadata in the expected order
and blocking known updater attacks, these unit tests only work with the
reference implementation.  Conformance testing should instead work across
different languages and platforms.  To achieve the preceding aim, the
specification can endorse an official tool, compatible with any implementation,
and cover how an implementation can be set up for conformance testing.

# Motivation

Adopters of the framework who have written implementations have tried testing
for conformance by (1) verifying that metadata generated in some language X
matches that of the reference implementation, and/or (2) reproducing the unit
tests of the reference implementation in language X.  In the first case, only
the metadata generated by X can be said to be conformant.  However, the client
would still need to be tested for the expected behavior when the generated
metadata is updated.  In the second case, the implementation is said to be
conformant depending on how thoroughly the unit tests are reproduced in X.
There are bound to be inconsistencies between both sets of unit tests, and
improvements in TUF testing or changes to TUF would result in a need for
implemeters to add test code in parallel, so a single tool is preferable.  A
single tool for conformance testing can avoid issues with interoperability,
duplicate work, ensuring update behavior as intended by the designers of the
framework, and most importantly it can ensure that an updater is secure against
the attacks and weaknesses listed in [section
1.5.2](https://github.com/theupdateframework/tuf/blob/6fde6222c9c6abf905ef4a56cf56fe35c4a85e14/docs/tuf-spec.txt#L124-L181)
(Goals for specific attacks to protect against) of the specification.  The
official tool is publicly available and runnable by anyone who wishes to test
an implementation.

An implementation can be said to be TUF-compliant if it passes conformance
testing with the official tool.

# Rationale

Developers need a convenient way of verifying whether an implementation
conforms to the specification.  One solution is to define, and ideally
automate, the expected outcome of an update request given different sets of
input metadata.  If an implementation is given the Root file and instructed to
download a particular package, does it correctly download the required
top-level metadata and the requested package?  Does it do so while still
preventing the attacks listed in the specification?  Consequently, an
implementation of the framework would need some way of accepting given metadata
and indicating when it has detected a particular attack.

This TAP prescribes that an implementation, or a wrapper script for it, accept
a set of command-line arguments, which are defined here, and exit with return
codes under certain conditions (e.g., to signal that a Freeze attack was
detected).  A fixed set of arguments is needed so that conformance testing is
consistent across different languages.  In turn, the conformance tester will
execute the implementation with different sets of metadata and verify its exit
codes for numerous outcomes.  The conformance tester also requires a minimum
number of arguments so that it can thoroughly cover all potential outcomes that
it wishes to test.  It should be noted, however, that the implmentation does
not necessarily have to be the updater used in production, only that it should
function as defined in this TAP for conformance testing.

An implementation under test will need to accept command-line arguments that
(1) indicate the target file to download when the program initiates an update,
(2) a directory containing the metadata and targets provided to the updater,
and (3) where requested metadata and target files are saved after a request
is made by the updater.  Specifically, the implementation needs to accept
these arguments as follows:

```Bash
$ command foo.tgz tmp/remote-metadata tmp/metadata tmp/targets
```

A Python example:

```Bash
$ python example_updater.py
  --file foo.tgz
  --remote-metadata tmp/remote-metadata
  --metadata tmp/metadata
  --targets tmp/targets
```

In turn, the conformance tester executes this command when it runs its suite of
conformance tests, which will consist of testing for things like validating the
metadata downloaded by the updater and verifying that the following attacks are
blocked:

```
(1) Arbitrary installation
(2) endless data
(3) extraneous dependencies
(4) fast-forward
(5) indefinite freeze
(6) malicious mirrors
(7) mix-and-match
(8) rollback
(9) slow retrieval
(10) key compromise.
```

While testing, the conformance tester verifies that the expected metadata
and update files are downloaded, and examine the return codes of the program
when attacks on the updater are present, which are defined later in the
`Specification` section of this TAP.  Note that the conformance tester is in
control of the repository specified on the command-line, and so it  can test
for various conditions and input metadata.

As for running conformance testing, the conformance tester accepts a
command-line option (and others, which will be covered later) that points to
the location of a configuration file:

```Bash
$ python conformance_tester.py
  --config tmp/.tuf-tester.yml
```

The configuration file includes the command that it should execute to run the
updater, and other restrictions such as the cryptography key types supported by
the updater, the number of root keys, thresholds, etc.  Why is a configuration
file needed?  There are restrictions set by different implementations that,
although they abide by the specification, are not shared across all
implementations of the specification.  For example, the Go implementation might
only support ECDSA keys, whereas another might support Ed25519 and RSA keys.

Before beginning conformance testing, the conformance testing tool will
generate a `root.json` according to the restrictions set in `.tuf-tester.yml`,
save it to --metadata tmp/metadata, populate and start a TUF repository, and
execute the update command.  The updater should load tmp/metadata/root.json,
refresh metadata accordingly, and fetch the target file.

The update procedure of the program, which is to refresh metadadata and
download a single target file, is sufficient to cover all the requirements set
by the specification [TODO: at least this is my conclusion, but I am open to
feedback].  As brief examples: the tool can start the update program and feed
it the correct metadata and target file when the requests are made.  It will
inspect the local metadata directory to ensure that the correct metadata was
downloaded, that they are signed properly, and that the update program succeeds
with a return code of `0`.  The tool can test the program for detection of a
slow retrieval attack by starting a server that provides data at a slow rate,
and confirming that the program returns a code of `5` (a return code of `5` is
defined in this TAP to mean that a slow retrieval error has occurred).

# Specification

The conformance tester stores `root.json` in the metadata directory indicated
on the command line (e.g., `tmp/metadata` above).  The root file is generated
according to the restrictions set in the configuration file.

The command to execute the conformance testing tool is:

```Bash
$ python conformance_tester.py
  --config tmp/.tuf-tester.yml
```

The conformance tester returns `0` if the implementation complies with the
specification.

conformance_tester.py returns a non-zero return code to signal a failure.
Optionally, a list of the conformance tests that the updater failed is printed
or logged.

An example of a `.tuf-tester.yml` configuration file for a Python updater:

```
# The command that the conformance tester executes to verify compliant_updater.py's
# conformity with the specification.
command: "python compliant_updater.py
  --file foo.tgz
  --repo http://localhost:8001
  --metadata tmp/metadata
  --targets tmp/targets"

# compliant_updater.py supports the following keytypes.
keytype: ed25519, ecdsa

# compliant_updater.py expects the Root file to be signed by a max of 3 different keys.
number-of-root-keys: 3

# Minimally, the Root file MUST be signed by at least 2/3 Root keys.
root-threshold: 2
...
```
The updater is expected to generate the following return codes in the following
situations:
[TODO: These return codes are not yet finalized]

```
return code      result
-----------      ------
0                success
1                unsigned metadata error
2                unknown target error
3                malicious target
4                rollback error
5                slow retrieval error
6                endless data error
...
```

## Example

Suppose a developer wants to verify that his Python implementation is compliant with
the specification.  He can begin by creating a script that accepts input
metadata and, when certain attacks are present, exits with the return codes
defined in this TAP.  The script can simply be an interface, or wrapper, to the
developer's actual Python implementation, which in production raises exceptions when
an error occurs. Furthermore, imagine the implementation might use a different command-line
interface from the one used by the script.  The developer's script, which behaves
according to this TAP, can look something like [this](https://github.com/theupdateframework/tuf/blob/tap7/tuf/scripts/conformance_tester/compliant_updater.py).

A user can run the developer's script, `compliant_updater.py`, to initiate a
normal update (e.g., to download the foo.tgz package).  In this case, the
script refreshes top-level metadata to ensure it has the latest repository
information, downloads the requested foo.tgz file, and exit with a return code
of 0.  The output after running the script (and verifying its return code with
the `echo $?` command) would look as follows:

```Bash
$ python compliant_updater.py
  --file foo.tgz
  --repo http://localhost:8001
  --metadata /tmp/metadata
  --targets /tmp/targets

$ echo $?
0
```

Similarly, the conformance tool is able to execute the script with the same
command-line arguments and examine the outcome.  For instance, the conformance
tool can examine the metadata that is saved to /tmp/metadata and confirm that
the Snapshot, Targets, and Timestamp metadata were saved to the /tmp/metadata
directory. (And according to the Root file that was loaded from /tmp/metadata
prior to the start of the update call, and generated by the conformance tool).
Additionally, it can compare the `foo.tgz` saved to /tmp/targets with the valid
one provided by the server indicated with the -`-repo` command-line option.


`compliant_updater.py` can also be tested by the conformance tool against the
known updater attacks, including the slow retrieval attack.  In the following
execution of the script, assume the repository specified in the --repo
command-line option provides data at a slow rate, causing clients to never
complete the update:


```Bash
$ python compliant_updater.py
  --file foo.tgz
  --repo http://localhost:8001
  --metadata /tmp/metadata --targets /tmp/targets

Error: Download was too slow. Average speed: 0.0 bytes per second.

$ echo $?
5
```

As before, the conformance tool is able to use this excution of the script to
verify that the expected return code of 5 is returned, and that certain
top-level metadata and the foo.tgz were unsuccessfully saved to the
/tmp/metadata and /tmp/targets directories, respectively.

Now, suppose that the Python implementation had the following restrictions:

```
(1) metadata is encoded in DER (rather than JSON)
(2) only Ed25519 keys are used and listed in metadata
(3) the Root file must be signed by 1 out of 2 keys (i.e., threshold of 1)
```

Items 2 & 3, of the list above, can be configured with the conformance tool via
its `.tuf-tester.yml` configuration file.  The configuration file can be edited
by the developer to list:

```
command: "python compliant_updater.py
  --file foo.tgz
  --repo http://localhost:8001
  --metadata tmp/metadata
  --targets tmp/targets"

keytype: ed25519
number-of-root-keys: 2
root-threshold: 1
```

Next, since the developer's setup uses DER metadata (rather than JSON), the
conformance tool would have to incorporate metadata that the developer's script
and Python implementation can handle.  For this task, the developer
would need to provide the conformance tool a path to a program that converts
JSON to DER metadata.  In this way, prior to calling the developer's  script and
initiating an update, the conformance tool can call the external program to
convert JSON metadata into DER format.

The command, and its output, that a user can run to test the developer's Python
implementation for conformance would resemble the following:

```Bash
$ python conformance_tester.py
  --config tmp/.tuf-tester.yml
  --convert-metadata path/to/convert-json-to-der.py

normal update: check.
blocked slow retrieval attack: check.
blocked rollback attack: check.
key revocation: check.
blocked endless data attack: check.
...

Congratulations! The implementation under test appears to conform with the TUF
specification.  More detailed info on the test results was saved to
test-results.txt

$
```

A JSON-to-DER converter, `convert_signed_metadata_to_der()`, can be found
[here](https://github.com/awwad/tuf/blob/36dbb7b8a800dab407fe9ab961155ef0a6d9f7c9/tuf/asn1_codec.py#L156-L352).
Those curious as to how JSON metadata can be converted to another encoding can
use the linked example to learn more.

Lastly, a summary of the steps followed to test an updater for conformance with
the specification is provided next.

```
(1) provide interface to updater that accepts metadata and exits with the
    TAP 7 return codes
(2) configure conformance tool to abide by the adopter's repository restrictions
(3) configure conformance tool to convert JSON metadata to the encoding used
    by the adopter, if necessary
(4) run conformance tool and confirm that all tests pass.
```

# Security Analysis

This TAP does not detract from existing security guarantees because it does not
propose architectual changes to the specification.

# Backwards Compatibility

This TAP does not introduce any backwards incompatibilities.

# Augmented Reference Implementation


A git branch containing the official tool for conformance testing and a client
set up for conformance testing:
https://github.com/theupdateframework/tuf/tree/tap7/tuf/scripts/conformance_tester

# Copyright

This document has been placed in the public domain.
